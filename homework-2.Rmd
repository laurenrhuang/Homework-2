---
title: "Homework 2"
author: "PSTAT 131/231"
output:
  pdf_document:
    toc: yes
  html_document:
    toc: yes
    toc_float: yes
    code_folding: show
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, message = FALSE,
                      warning = FALSE)
```

## Linear Regression

For this lab, we will be working with a data set from the UCI (University of California, Irvine) Machine Learning repository ([see website here](http://archive.ics.uci.edu/ml/datasets/Abalone)). The full data set consists of $4,177$ observations of abalone in Tasmania. (Fun fact: [Tasmania](https://en.wikipedia.org/wiki/Tasmania "Tasmania") supplies about $25\%$ of the yearly world abalone harvest.)

The age of an abalone is typically determined by cutting the shell open and counting the number of rings with a microscope. The purpose of this data set is to determine whether abalone age (**number of rings + 1.5**) can be accurately predicted using other, easier-to-obtain information about the abalone.

The full abalone data set is located in the `\data` subdirectory. Read it into *R* using `read_csv()`. Take a moment to read through the codebook (`abalone_codebook.txt`) and familiarize yourself with the variable definitions.

Make sure you load the `tidyverse` and `tidymodels`!

### Question 1

Your goal is to predict abalone age, which is calculated as the number of rings plus 1.5. Notice there currently is no `age` variable in the data set. Add `age` to the data set.

Assess and describe the distribution of `age`.
```{r}
library(tidyverse)
library(tidymodels)

# read in the data
abalone <- read_csv("C:/Users/cupca/OneDrive/Documents/UCSB/Fall2022/PSTAT131/homework-2/data/abalone.csv")

# add age as a variable
abalone_w_age <- abalone %>% mutate(age = rings + 1.5)
abalone_w_age

# simple histogram of abalone age
hist(abalone_w_age$age,
     xlab = "abalone age",
     main = "Histogram of abalone age")
```

Answer: After making a histogram of the abalone age variable, it seems that age is approximately normally distributed, showing a bell-shaped curve.


### Question 2

Split the abalone data into a training set and a testing set. Use stratified sampling. You should decide on appropriate percentages for splitting the data.

*Remember that you'll need to set a seed at the beginning of the document to reproduce your results.*
```{r}
set.seed(3435)

# preparing data for splitting
abalone_w_age <- abalone_w_age %>%
  select(-rings) %>% # remove rings variable
  mutate(type=as.factor(type)) # convert type variable to factor type

# split into training/testing sets
abalone_split <- initial_split(abalone_w_age, prop = 0.80,
                                strata = age)
abalone_train <- training(abalone_split)
abalone_test <- testing(abalone_split)
```

### Question 3

Using the **training** data, create a recipe predicting the outcome variable, `age`, with all other predictor variables. Note that you should not include `rings` to predict `age`. Explain why you shouldn't use `rings` to predict `age`.

Steps for your recipe:
1.  dummy code any categorical predictors

2.  create interactions between

    -   `type` and `shucked_weight`,
    -   `longest_shell` and `diameter`,
    -   `shucked_weight` and `shell_weight`

3.  center all predictors, and

4.  scale all predictors.

You'll need to investigate the `tidymodels` documentation to find the appropriate step functions to use.
```{r}
# recipe (do not include rings)
abalone_recipe <- recipe(age~., data = abalone_train) %>%
  step_dummy(all_nominal_predictors()) %>% # dummy code categorical predictors
  step_interact(terms = ~ starts_with("type"):shucked_weight) %>% # create interactions
  step_interact(terms = ~ longest_shell:diameter) %>%
  step_interact(terms = ~ shucked_weight:shell_weight) %>%
  step_center(all_predictors()) %>% # center predictors
  step_scale(all_predictors()) # scale predictors
```

Answer: We should not include rings to predict age because age is calculated based on rings (rings + 1.5). If we used rings, it would be like using a scaled version of the outcome as a predictor to help predict the outcome, which doesn't make much sense.


### Question 4

Create and store a linear regression object using the `"lm"` engine.
```{r}
# create model, store linear regression object
lm_model <- linear_reg() %>% 
  set_engine("lm")
```

### Question 5

Now:
1.  set up an empty workflow,
2.  add the model you created in Question 4, and
3.  add the recipe that you created in Question 3.
```{r}
lm_wflow <- workflow() %>% # empty workflow
  add_model(lm_model) %>%  # add model
  add_recipe(abalone_recipe) # add recipe

lm_fit <- fit(lm_wflow, abalone_train) # see how our fitted model did

lm_fit %>% 
  # This returns the parsnip object:
  extract_fit_parsnip() %>% 
  # Now tidy the linear model object:
  tidy()
```

### Question 6

Use your `fit()` object to predict the age of a hypothetical female abalone with longest_shell = 0.50, diameter = 0.10, height = 0.30, whole_weight = 4, shucked_weight = 1, viscera_weight = 2, shell_weight = 1.
```{r}
# new observation to predict
new_abalone <- data.frame(type=as.factor("F"),
                          longest_shell=0.50,
                          diameter=0.10,
                          height=0.30,
                          whole_weight=4,
                          shucked_weight=1,
                          viscera_weight=2,
                          shell_weight=1)
new_abalone <- as_tibble(new_abalone) # convert to tibble

abalone_train_res <- predict(lm_fit, new_data = new_abalone) # use model to predict
abalone_train_res
```

### Question 7

Now you want to assess your model's performance. To do this, use the `yardstick` package:

1.  Create a metric set that includes *R^2^*, RMSE (root mean squared error), and MAE (mean absolute error).
2.  Use `predict()` and `bind_cols()` to create a tibble of your model's predicted values from the **training data** along with the actual observed ages (these are needed to assess your model's performance).
3.  Finally, apply your metric set to the tibble, report the results, and interpret the *R^2^* value.
```{r}
# metric set
abalone_metrics <- metric_set(rmse, rsq, mae)

# tibble of predicted values
abalone_train_res <- predict(lm_fit, new_data = abalone_train %>% select(-age))
abalone_train_res %>% 
  head()

# add actual observed ages
abalone_train_res <- bind_cols(abalone_train_res, abalone_train %>% select(age))
abalone_train_res %>% 
  head()

# apply metric set to tibble
abalone_metrics(abalone_train_res, truth = age, 
                estimate = .pred)
```

Answer: R^2 measures the proportion of variability in the outcome Y (age of the abalone), that can be explained through the predictor X (longest_shell, diameter, height, whole_weight, shucked_weight, viscera_weight, and shell_weight). So according to the metric set, it seems that there is about 0.55 variability in abalone age that can be accounted for by our predictors.
